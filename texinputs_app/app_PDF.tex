\tiny

\textbf{P. Pani}

Dear experts and DMWG contributors, since there are a number of parallel
threads discussing the most appropriate flavour scheme to use for the
2HDM generation, I would like to converge the discussion in a single
place. My take on the issue is that the flavour scheme is important for
b-initiated processes and that the default choice for the other
processes is usually a 5-flavour scheme. This would include mono-H/Z,
mono-jet and DM+tt. Would you agree with this choice? Again my take is
that for the 2HDM+a model, the only process where b-initiated diagrams
have a relevant impact is bb+chichi (unless you go to very high tan-beta
values). For this we either make a complete study and use the difference
as uncertainty (see Uli's extensive explanation below) or make a choice
and clearly state it, since both 4f and 5f schemes have pros and cons
for this process. I would personally also for DM+bb use the 5F choice
for the following reasons: 1) consistency with the other final states,
since otherwise an appropriate 4F NLO UFO, compatible with the 4F
assumptions, need to be provided and used. 2) the scale of the process
will be driven by ma \textgreater{} 150 GeV, which should be high enough
to be in the "high-Higgs masses" regime discussed below where the
Santander matching agrees better with the 5F scheme. Assigning the
difference between 4 and 5 flavour estimate as uncertainty on top of
this choice would be my preferred solution. Finally, for NLO generation
we would like to confirm the following PDF choice: 4F:
NNPDF30\_nlo\_as\_0118\_nf\_4 5F: NNPDF30\_nlo\_as\_0118 

\textbf{U. Haisch}

regarding your recommendation of using the 5F scheme - can you to please
explain why this is the correct thing to do in both cases? (DM+bb,
DM+tt) + like in tt+Higgs i would calculate tt+MET in the 5F scheme.
this is the obvious choice since all scales involved in the process are
much larger than the bottom mass and thus the b can be treated as
effectively massless as for all processes that feature b quarks at the
level of the hard-scattering process, there are two viable approaches to
compute the bb+Higgs or bb+MET cross section. in the 4F scheme, b quarks
are treated as massive particles, hence no b can appear in the initial
state of the partonic scattering process. this is relevant for those
cases where the physical mass of the b quark is considered as a hard
scale and implies that observables with tagged final-state b quarks are
well defined (and thus can b computed reliably). at any order in
perturbation theory the 4F scheme involves terms log(m\_b/Q) where Q is
the characteristic scale of the g -\textgreater{} bb splitting needed to
produce the final state b's. These logarithmically enhanced terms remain
small as long as Q = O(m\_b), but can spoil the perturbative convergence
when Q \textgreater{}\textgreater{} m\_b. such terms are generally dealt
with by reorganising the perturbative series while resuming them the
logarithms to all orders in alpha\_s. this is precisely achieved by
working in the second viable approaches to compute the bb+Higgs or
bb+MET cross section, i.e. the 5F scheme, which is particularly
important when the characteristic of an observable is that of being
dominated by such logarithms. in this scheme, one assumes massless b
quarks at the level of the short-distance cross section, which are
therefore treated at equal footing as the other light quarks and may
appear as initial state particles. the potentially large logarithms are
effectively resummed through the DGLAP evolution of the b-quark PDFs it
is clear from the discussion above that 4F scheme computations do not
account for logarithmic terms beyond the first few, while 5F scheme
results lack power-suppressed terms (m\_b/Q)\^{}n since m\_b = 0 in the
5F scheme. if either of these properties is important the other scheme
must be preferred. being highly observable dependent, at least for
inclusive quantities neither resummation nor mass effects are dominant
and the two approaches lead to generally similar results. for inclusive
observables the 5F scheme has however the technical advantage of being
much simpler, rendering calculations beyond NLO possible, which is very
hard in the 4F scheme. for more exclusive observables, in particular
regarding the final-state b quarks, the 5F scheme loses its advantage,
because it has compared to the 4F scheme much more limited information
on the final-state kinematics of the bb system. this problem of the 5F
can be alleviated by matching the fixed-order computation to parton
showers (PS) which however only provides leading logarithmic accuracy in
general from the above it should be somewhat obvious that in the case of
bb+Higgs or bb+MET it is not entirely clear whether the 5F or 4F scheme
is preferable. in the case of bb+Higgs this issue has been studied in
detail. see for instance figures 263 and 264 in
https://arxiv.org/pdf/1610.07922.pdf from these figures one can conclude
that for large Higgs masses and sufficiently inclusive measurements the
5F scheme is probably preferable over the 4F scheme since it agrees
better with the Santander matching, FONLL-B and NLO+NNLLpartial+ybyt
results. for small Higgs masses the opposite conclusions can be drawn
and the 4F scheme seems more appropriate i think that the conclusions
that one can draw in the case of the Higgs also apply to the MET case;
if i am correct this means that the best choice of scheme will depend on
how light or heavy the DM mediator is in practice i think one way to
proceed is to generate the signal both in the 5F and 4F scheme and take
the difference to assess the theoretical error; in principle this should
be done at NLO+PS and MadGraph5\_aMC@NLO should be able to do this; one
could also think about implementing a scheme like Santander matching,
FONLL-B and NLO+NNLLpartial+ybyt. personally, i think however that this
is an overkill in the absence of a signal in the bb+MET, tt+MET, t+MET,
etc. channels 2. from your answer I understand it might take time to
update the UFO to be suitable to use at NLO. specifically for the
DM+bb/DM+tt final states - do you have an estimation if running at NLO
is something that might have a large impact on the cross sections and on
the kinematical distributions, comparing to LO? + i think that the K
factors and changes in the distributions are not very big if the
mediator is heavy; in case it is light NLO+PS effects will be important
in particular in the 5F scheme; for the case of a light mediator the
importance of the effects also depends significantly on the experimental
analysis and the cuts that are put on the final-state bottom quarks. i
think a conservative approach would be to proceed as described above and
first generate LO 5F and 4F samples, including also scale variation and
PDF uncertainties into the theory error. at low mediator masses this is
likely to result in a very large error (cf. figure 246 in
https://arxiv.org/pdf/1610.07922.pdf) that will make it difficult to set
bounds on the parameters of the model via bb+MET

\textbf{F. Maltoni}

Regarding the
choice of scheme, 4F or 5F, I would like to state my personal opinion.
Considering that predictions are needed for a search (not a SM
measurement) and this search is made through simplified models (not a
fully fledged DM candidate model), I think it is appropriate to keep
simplicity/easiness of reproducibility among the most important
requirements. Including NLO QCD corrections is also important for both
accuracy and precision and choosing a scheme where these are simple to
compute is useful/handy. I would therefore advise to generically use a
5F scheme, *whenever possible/meaningful*. This will make predictions
simpler to generate and use, and also easier to go to NLO in QCD. The
proviso in the asterisks is to keep in mind that if the scalar mediator
mass starts to be comparable to that of the bottom quark (let's say
below 20-30 GeV), a 4F might become more appropriate (even though might
not be necessary if a large mET is required and the scalar is therefore
boosted, in which case a 5F will be still fine). I think that in case of
doubt a check between predictions obtained in the 4F and 5F could be
useful, even though one has to exercise *caution*, as this is not really
straightforward to make such a comparison (even at LO) and to interpret
it. For this reason, I would not advise (at least at this stage) you to
use the 4F and 5F differences as a systematic uncertainty to be added to
the TH predictions, and just go with usual scale/PDF uncertainties.

\normalsize
